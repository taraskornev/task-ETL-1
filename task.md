# Проєкт: Аналіз та Очищення Даних UK-500 (Pandas)

## Опис проєкту
Цей навчальний проєкт спрямований на опрацювання реального CSV-датасету **UK-500**, що містить профілі 500 осіб: контактні дані, email, адреси, компанії, вебсайти та іншу інформацію.

**Мета проєкту — відтворити типовий робочий процес дата-аналітика:**

`ETL → очищення → фільтрація → трансформація → агрегування → експорт результатів.`

---

## Мета та цілі

### Мета
Опанувати базові та середні навички роботи з **Pandas**, використовуючи реальний набір даних.

### Цілі:
- Завантажити та дослідити CSV-файл.  
- Провести первинний EDA.  
- Очистити дані та згенерувати нові ознаки.  
- Виконати фільтрацію, групування, вибірки.  
- Підготувати проміжні та фінальні результати у форматах CSV/Excel.  
- Продемонструвати навички Data Cleaning & Feature Engineering.

---

## Вхідні дані

| Файл          | Опис |
|---------------|-------|
| **uk-500.csv** | Датасет (500 записів), містить персональні та контактні дані |

**Посилання на датасет:**  
https://s3-eu-west-1.amazonaws.com/shanebucket/downloads/uk-500.csv

---

## Завдання (як від менеджера до аналітика)

Необхідно виконати повний цикл обробки даних:

1. **Імпорт та діагностика**
2. **Перевірка якості даних**
3. **Очищення та формування нових колонок**
4. **Фільтрація та вибірки**
5. **Групування та статистика**
6. **Експорт результатів**
7. **Документування висновків**

---

## План Реалізації (покроковий)

---

### **1. Імпорт та первинне дослідження**

1. Завантажити `uk-500.csv` за допомогою `pd.read_csv()`.
2. Переглянути структуру:
   - `df.head()`
   - `df.info()`
   - `df.describe()`
3. Перевірити якість:
   - пропущені → `df.isna().sum()`
   - дублікати → `df.duplicated().sum()`

---

### **2. Очищення даних**

- Видалити непотрібні колонки (за рішенням аналітика).
- Привести `email` та `web` до нижнього регістру.
- Очистити `phone` та `fax` від пробілів/символів.
- Стандартизувати формат текстових полів.

---

### **3. Створення нових колонок (Feature Engineering)**

| Нова колонка      | Опис |
|------------------|------|
| `full_name`      | Ім’я + прізвище |
| `email_domain`   | Домен email |
| `city_length`    | Довжина назви міста |
| `is_gmail`       | Boolean: чи email з gmail.com |

---

### **4. Фільтрація даних**

Створити підвибірки:

- користувачі з доменом **gmail.com**  
- працівники компаній з “LLC” або “Ltd”  
- люди з міста **London**  
- компанії з назвою ≥ 4 слів  

Використовувати:
- `df.loc[]`
- `str.contains()`
- `df.apply()`

---

### **5. Позиційна вибірка (iloc)**

- Перші 10 рядків + колонки 2–5  
- Кожний 10-й рядок  
- 5 випадкових рядків → `.sample(5)`

---

### **6. Групування та статистика**

Створити агрегати:

- кількість людей у кожному місті  
- ТОП-5 міст  
- ТОП-5 email-доменів  
- кількість унікальних доменів  

Використати:
- `groupby()`
- `value_counts()`
- `agg()`

---

### **7. Експорт результатів**

| Файл | Містить |
|------|---------|
| **uk500_clean.csv** | очищений датасет |
| **gmail_users.csv** | вибірка Gmail-користувачів |
| **stats.xlsx** | ТОП-міста та ТОП-домени у окремих вкладках |

---

### **8. Висновки**

Додати розділ, де описати:

- що було зроблено  
- які проблеми знайдено в датасеті  
- найкорисніші трансформації  
- цікаві вибірки та висновки  
- що можна покращити у майбутньому  

---

## Необхідні бібліотеки

```python
import pandas as pd
import numpy as np
